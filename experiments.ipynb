{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from src.model_rt import RealtimeModel, svc, linear_svc, nu_svc, lda, qda\n",
    "from src.utils_import import load_data\n",
    "from src.utils_preprocess import split_data, compute_energy_matrix_and_labels\n",
    "from src.utils_clustering import create_cluster, cluster_mapping\n",
    "from src.utils_preprocess import *\n",
    "\n",
    "\n",
    "random.seed(1337)\n",
    "np.random.seed(1337)\n",
    "\n",
    "# Asumption: all signals consist of 50k samples\n",
    "n_samples = 50000\n",
    "interv = 1024 # Hyperparameter 1\n",
    "array_length = (n_samples // interv) - 1\n",
    "n_frec_div = 32 # Hyperparameter 2\n",
    "\n",
    "# Load data\n",
    "signals_clean = load_data('dataset/Jamming/Clean', 'dataset/Jamming/metadata.csv')\n",
    "signals_narrowband = load_data('dataset/Jamming/Narrowband', 'dataset/Jamming/metadata.csv')\n",
    "signals_wideband = load_data('dataset/Jamming/Wideband', 'dataset/Jamming/metadata.csv')\n",
    "\n",
    "# Partition train=0.8, test=0.2\n",
    "clean_train, clean_test = split_data(signals_clean, 0.8)\n",
    "narrowband_train, narrowband_test = split_data(signals_narrowband, 0.8)\n",
    "wideband_train, wideband_test = split_data(signals_wideband, 0.8)\n",
    "\n",
    "train = clean_train + narrowband_train + wideband_train\n",
    "test = clean_test + narrowband_test + wideband_test\n",
    "\n",
    "print(f\"Nº señales entrenamiento: {len(train)}\")\n",
    "print(f\"Nº señales test: {len(test)}\")\n",
    "\n",
    "random.shuffle(train)\n",
    "random.shuffle(test)\n",
    "\n",
    "class_mapping = {\"Clean\": 0, \"Narrowband Start\": 1, \"Narrowband Stop\": 2, \"Wideband Start\": 3, \"Wideband Stop\": 4}\n",
    "class_unmapping = {v:k for k,v in class_mapping.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = train[0][\"Data\"] # Clean\n",
    "f = signal_interval(d)\n",
    "print(f.shape)\n",
    "plt.plot(f[20])\n",
    "plt.show()\n",
    "\n",
    "d = train[1][\"Data\"] # Narrowband\n",
    "start = train[1]['JammingStartTime']//1024\n",
    "print(train[1])\n",
    "f = signal_interval(d)\n",
    "print(f.shape)\n",
    "plt.plot(f[start-1])\n",
    "plt.plot(f[start])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "d = train[6][\"Data\"] # Wideband\n",
    "start = train[6]['JammingStartTime']//1024\n",
    "print(train[6])\n",
    "f = signal_interval(d)\n",
    "print(f.shape)\n",
    "plt.plot(f[start-1])\n",
    "plt.plot(f[start])\n",
    "plt.show()\n",
    "\n",
    "t = f[start-2:start+1]\n",
    "print(\"-\"*100)\n",
    "print(t)\n",
    "e=energy_arrays(t, 16)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) -- Train --\n",
    "\n",
    "# Building energy arrays for each train signal (x=window samples, y=frecuency divisions z=signal)\n",
    "train_energy_dif_matrix, sample_labels = compute_energy_matrix_and_labels(train, n_samples, interv, n_frec_div, class_mapping, balance_data=True)\n",
    "\n",
    "\"\"\"\n",
    "# Creating K-Means model based on energy arrays\n",
    "cluster = create_cluster(train_energy_dif_matrix, k=5)\n",
    "print(f\"\\n--- Centros de cluster ---\\n{cluster.cluster_centers_}\") \n",
    "\n",
    "# Mapping cluster to original classes\n",
    "cluster_map = cluster_mapping(cluster.labels_, sample_labels, class_mapping)\n",
    "print(f\"\\nMapping clusters to predominant classes: {cluster_map}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) -- Test -- \n",
    "\n",
    "test_energy_dif_matrix, y_true = compute_energy_matrix_and_labels(test, n_samples, interv, n_frec_div, class_mapping)\n",
    "\n",
    "\"\"\"\n",
    "y_pred = [cluster_map[label] for label in cluster.predict(test_energy_dif_matrix)]\n",
    "# Nota: por el momento predice en exceso clase 1 (corregir desbalanceo, clase mayoritaria tiene muchas más ocurrencias)\n",
    "print(np.bincount(y_pred))\n",
    "\n",
    "# True signal classification\n",
    "#signal_true = np.zeros(len(test), dtype=np.int8)\n",
    "#for i, signal in enumerate(test):\n",
    "#    signal_true[i] = class_mapping[signal[\"Class\"]]\n",
    "\n",
    "# Predicted signal classification\n",
    "#signal_pred = predict_labels(y_pred, N=len(test), array_length=array_length)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) -- Train --\n",
    "\n",
    "svc_model = svc(train_energy_dif_matrix, sample_labels)\n",
    "lin_svc = linear_svc(train_energy_dif_matrix, sample_labels)\n",
    "nu_SVC = nu_svc(train_energy_dif_matrix, sample_labels)\n",
    "lda_model = lda(train_energy_dif_matrix, sample_labels)\n",
    "qda_model = qda(train_energy_dif_matrix, sample_labels)\n",
    "\n",
    "# 2) -- Test -- \n",
    "\n",
    "y_pred = svc_model.predict(test_energy_dif_matrix)\n",
    "y_pred2 = lin_svc.predict(test_energy_dif_matrix)\n",
    "y_pred3 = nu_SVC.predict(test_energy_dif_matrix)\n",
    "y_pred4 = lda_model.predict(test_energy_dif_matrix)\n",
    "y_pred5 = qda_model.predict(test_energy_dif_matrix)\n",
    "\n",
    "# 3) -- Metrics --\n",
    "\n",
    "print(\"\\n-- SVC --\")\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nAccuracy: {acc}\")        \n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "#\n",
    "\n",
    "print(\"\\n-- Linear SVC --\")\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred2)\n",
    "print(f\"\\nAccuracy: {acc}\")        \n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred2)\n",
    "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred2))\n",
    "\n",
    "#\n",
    "\n",
    "print(\"\\n-- Nu SVC --\")\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred3)\n",
    "print(f\"\\nAccuracy: {acc}\")        \n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred3)\n",
    "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred3))\n",
    "\n",
    "#\n",
    "\n",
    "print(\"\\n-- LDA --\")\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred4)\n",
    "print(f\"\\nAccuracy: {acc}\")        \n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred4)\n",
    "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred4))\n",
    "\n",
    "#\n",
    "\n",
    "print(\"\\n-- QDA --\")\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred5)\n",
    "print(f\"\\nAccuracy: {acc}\")        \n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred5)\n",
    "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = StratifiedKFold(5)\n",
    "model = KNeighborsClassifier()\n",
    "parameters = {\"n_neighbors\":list(range(1,31)), \"weights\":(\"uniform\",\"distance\")}\n",
    "clf = GridSearchCV(model, parameters, cv=fold, refit=True)\n",
    "clf.fit(train_energy_dif_matrix, sample_labels)\n",
    "best_params = clf.best_params_ \n",
    "\n",
    "# leaf_size only affects execution time, so it's done separately\n",
    "model = KNeighborsClassifier(**best_params)\n",
    "clf = GridSearchCV(model, {\"leaf_size\":[20,30,50,100,200,300,400]}, cv=fold, refit=True)\n",
    "clf.fit(train_energy_dif_matrix, sample_labels)\n",
    "best_index = np.argmin(clf.cv_results_['mean_fit_time'])\n",
    "best_params['leaf_size'] = clf.cv_results_['params'][best_index]['leaf_size']\n",
    "\n",
    "model = clf.best_estimator_\n",
    "y_hat = model.predict(test_energy_dif_matrix)\n",
    "acc = accuracy_score(y_true, y_hat)\n",
    "\n",
    "print(\"KNN\")\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_true, y_hat)\n",
    "print(f\"\\nAccuracy: {acc}\")        \n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_hat)\n",
    "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "\n",
    "# Classification Report\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realtime_model = RealtimeModel(svc_model, classes = {\"Clean\": 0, \n",
    "                                                    \"Narrowband Start\": 1, \n",
    "                                                    \"Narrowband Stop\": 2, \n",
    "                                                    \"Wideband Start\": 3, \n",
    "                                                    \"Wideband Stop\": 4}, \n",
    "                                        class_map = {0: \"Clean\", \n",
    "                                                    1: \"Narrowband\", \n",
    "                                                    2: \"Clean\", \n",
    "                                                    3: \"Wideband\", \n",
    "                                                    4: \"Clean\"}, \n",
    "                                        class_type = {0: \"Clean\", \n",
    "                                                    1: \"Narrowband\", \n",
    "                                                    2: \"Narrowband\", \n",
    "                                                    3: \"Wideband\", \n",
    "                                                    4: \"Wideband\"},\n",
    "                                        offset=4,\n",
    "                                        nfft=interv, n_partitions=n_frec_div, verbose=True)\n",
    "#print(test[0][\"Data\"])\n",
    "pred = realtime_model.classificate_recordings(test)\n",
    "\n",
    "y_signal_true = [s[\"Class\"] for s in test]\n",
    "y_hat = [s[\"Class\"] for s in pred]\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_signal_true, y_hat)\n",
    "print(f\"\\nAccuracy: {acc}\")        \n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_signal_true, y_hat)\n",
    "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "\n",
    "# Classification Report\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_signal_true, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) -- Metrics --\n",
    "\n",
    "# Accuracy\n",
    "#acc = accuracy_score(signal_true, signal_pred)\n",
    "#print(f\"\\nAccuracy: {acc}\")        \n",
    "\n",
    "# Confusion Matrix\n",
    "#cm = confusion_matrix(signal_true, signal_pred)\n",
    "#print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "\n",
    "# Classification Report\n",
    "#print(f\"\\nClassification Report:\")\n",
    "#print(classification_report(signal_true, signal_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.mixture import GaussianMixture\n",
    "\n",
    "pca = PCA(2) \n",
    "X = test_energy_dif_matrix\n",
    "pca_data = pd.DataFrame(pca.fit_transform(X),columns=['PC1','PC2']) \n",
    "kmeans =create_cluster(X)\n",
    "pca_data['cluster'] = pd.Categorical(kmeans.labels_)\n",
    "#kmeans = GaussianMixture(n_components5)\n",
    "#pca_data['cluster'] = pd.Categorical(kmeans.fit_predict(X,sample_labels))\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "scatter = ax.scatter(pca_data['PC1'], pca_data['PC2'],c=pca_data['cluster'],cmap='Set3',alpha=0.1)\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    loc=\"upper left\", title=\"\")\n",
    "ax.add_artist(legend1)\n",
    "plt.title(\"Clustering classification\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2) \n",
    "X = test_energy_dif_matrix\n",
    "pca_data = pd.DataFrame(pca.fit_transform(X),columns=['PC1','PC2']) \n",
    "pca_data['cluster'] = pd.Categorical(y_true)\n",
    "#kmeans = GaussianMixture(n_components=5)\n",
    "#pca_data['cluster'] = pd.Categorical(kmeans.fit_predict(X,sample_labels))\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "scatter = ax.scatter(pca_data['PC1'], pca_data['PC2'],c=pca_data['cluster'],cmap='Set3',alpha=0.1)\n",
    "#legend1 = ax.legend(*scatter.legend_elements(),\n",
    "legend1 = ax.legend(scatter.legend_elements()[0], class_mapping.keys(), # WARNING: labels could be wrong\n",
    "                    loc=\"upper left\", title=\"\")\n",
    "ax.add_artist(legend1)\n",
    "plt.title(\"True classification\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(sample_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
