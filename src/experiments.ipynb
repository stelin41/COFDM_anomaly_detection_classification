{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from utils_import import load_data\n",
    "from utils_preprocess import split_data, compute_energy_matrix_and_labels\n",
    "from utils_clustering import create_cluster, cluster_mapping\n",
    "from utils_test import predict_labels\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "random.seed(1337)\n",
    "np.random.seed(1337)\n",
    "\n",
    "# Asumption: all signals consist of 50k samples\n",
    "n_samples = 50000\n",
    "interv = 1024 # Hyperparameter 1\n",
    "array_length = (n_samples // interv) - 1\n",
    "n_frec_div = 16 # Hyperparameter 2\n",
    "\n",
    "# Load data\n",
    "signals_clean = load_data('../dataset/Jamming/Clean', '../dataset/Jamming/metadata.csv')\n",
    "signals_narrowband = load_data('../dataset/Jamming/Narrowband', '../dataset/Jamming/metadata.csv')\n",
    "signals_wideband = load_data('../dataset/Jamming/Wideband', '../dataset/Jamming/metadata.csv')\n",
    "\n",
    "# Partition train=0.8, test=0.2\n",
    "clean_train, clean_test = split_data(signals_clean, 0.8)\n",
    "narrowband_train, narrowband_test = split_data(signals_narrowband, 0.8)\n",
    "wideband_train, wideband_test = split_data(signals_wideband, 0.8)\n",
    "\n",
    "train = []\n",
    "train.extend(clean_train)  \n",
    "train.extend(narrowband_train)  \n",
    "train.extend(wideband_train) \n",
    "test = [] \n",
    "test.extend(clean_test)  \n",
    "test.extend(narrowband_test) \n",
    "test.extend(wideband_test) \n",
    "\n",
    "print(f\"Nº señales entrenamiento: {len(train)}\")\n",
    "print(f\"Nº señales test: {len(test)}\")\n",
    "\n",
    "random.shuffle(train)\n",
    "random.shuffle(test)\n",
    "\n",
    "class_mapping = {\"Clean\": 0, \"Narrowband\": 1, \"Wideband\": 2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_preprocess import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d = train[0][\"Data\"] # Clean\n",
    "f = signal_interval(d)\n",
    "print(f.shape)\n",
    "plt.plot(f[20])\n",
    "plt.show()\n",
    "\n",
    "d = train[1][\"Data\"] # Narrowband\n",
    "start = train[1]['JammingStartTime']//1024\n",
    "print(train[1])\n",
    "f = signal_interval(d)\n",
    "print(f.shape)\n",
    "plt.plot(f[start-1])\n",
    "plt.plot(f[start])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "d = train[6][\"Data\"] # Wideband\n",
    "start = train[6]['JammingStartTime']//1024\n",
    "print(train[6])\n",
    "f = signal_interval(d)\n",
    "print(f.shape)\n",
    "plt.plot(f[start-1])\n",
    "plt.plot(f[start])\n",
    "plt.show()\n",
    "\n",
    "t = f[start-2:start+1]\n",
    "print(\"-\"*100)\n",
    "print(t)\n",
    "e=energy_arrays(t, 16)\n",
    "print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) -- Train --\n",
    "\n",
    "# Building energy arrays for each train signal (x=window samples, y=frecuency divisions z=signal)\n",
    "train_energy_dif_matrix, sample_labels = compute_energy_matrix_and_labels(train, n_samples, interv, n_frec_div, class_mapping)\n",
    "train_energy_dif_matrix = np.abs(train_energy_dif_matrix)\n",
    "# Creating K-Means model based on energy arrays\n",
    "cluster = create_cluster(train_energy_dif_matrix, k=3)\n",
    "print(f\"\\n--- Centros de cluster ---\\n{cluster.cluster_centers_}\") \n",
    "\n",
    "# Mapping cluster to original classes\n",
    "cluster_map = cluster_mapping(cluster.labels_, sample_labels, class_mapping)\n",
    "print(f\"\\nMapping clusters to predominant classes: {cluster_map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) -- Test -- \n",
    "\n",
    "test_energy_dif_matrix, y_true = compute_energy_matrix_and_labels(test, n_samples, interv, n_frec_div, class_mapping)\n",
    "test_energy_dif_matrix = np.abs(test_energy_dif_matrix)\n",
    "\n",
    "y_pred = [cluster_map[label] for label in cluster.predict(test_energy_dif_matrix)]\n",
    "# Nota: por el momento predice en exceso clase 1 (corregir desbalanceo, clase mayoritaria tiene muchas más ocurrencias)\n",
    "print(np.bincount(y_pred))\n",
    "\n",
    "# True signal classification\n",
    "signal_true = np.zeros(len(test), dtype=np.int8)\n",
    "for i, signal in enumerate(test):\n",
    "    signal_true[i] = class_mapping[signal[\"Class\"]]\n",
    "\n",
    "# Predicted signal classification\n",
    "signal_pred = predict_labels(y_pred, N=len(test), array_length=array_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) -- Metrics --\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(signal_true, signal_pred)\n",
    "print(f\"\\nAccuracy: {acc}\")        \n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(signal_true, signal_pred)\n",
    "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "\n",
    "# Classification Report\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(signal_true, signal_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "#from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "pca = PCA(2) \n",
    "X = np.abs(test_energy_dif_matrix)\n",
    "pca_data = pd.DataFrame(pca.fit_transform(X),columns=['PC1','PC2']) \n",
    "kmeans =KMeans(n_clusters=3).fit(X)\n",
    "pca_data['cluster'] = pd.Categorical(kmeans.labels_)\n",
    "#kmeans = GaussianMixture(n_components=3)\n",
    "#pca_data['cluster'] = pd.Categorical(kmeans.fit_predict(X,sample_labels))\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "scatter = ax.scatter(pca_data['PC1'], pca_data['PC2'],c=pca_data['cluster'],cmap='Set3',alpha=0.1)\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    loc=\"upper left\", title=\"\")\n",
    "ax.add_artist(legend1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = train[1][\"Data\"] # Narrowband\n",
    "start = train[1]['JammingStartTime']//1024\n",
    "\n",
    "#test_energy_dif_matrix[50000+start]\n",
    "np.argmax(sample_labels>0)\n",
    "print(np.argmax(test_energy_dif_matrix>0.1))\n",
    "print(sample_labels[159])\n",
    "#test_energy_dif_matrix[340:343]\n",
    "sample_labels[159]\n",
    "test_energy_dif_matrix[340:343]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(sample_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
